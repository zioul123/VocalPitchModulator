{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Walkthrough\n",
    "This is the notebook used to detail the data processing for training the Vocal Pitch Modulator.\n",
    "\n",
    "The goes through in detail (with plots and prints) how the data is organized. \n",
    "\n",
    "## Global variables/Imports\n",
    "Run these cells before running either of the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.io import wavfile\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "%aimport VPM\n",
    "from VPM import *\n",
    "%aimport Utils\n",
    "from Utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants that should not change without the dataset being changed\n",
    "n_pitches = 16\n",
    "n_vowels = 12\n",
    "n_people = 3\n",
    "\n",
    "# These dictionaries are more for reference than anything\n",
    "label_to_vowel = { 0: \"bed\",  1: \"bird\",   2: \"boat\",  3: \"book\", \n",
    "                   4: \"cat\",  5: \"dog\",    6: \"feet\",  7: \"law\",  \n",
    "                   8: \"moo\",  9: \"nut\",   10: \"pig\",  11: \"say\" }\n",
    "\n",
    "vowel_to_label = { \"bed\": 0,  \"bird\": 1,  \"boat\":  2, \"book\":  3,\n",
    "                   \"cat\": 4,  \"dog\":  5,  \"feet\":  6, \"law\":   7,\n",
    "                   \"moo\": 8,  \"nut\":  9,  \"pig\":  10, \"say\":  11}\n",
    "\n",
    "noteidx_to_pitch = {  0: \"A2\",   1: \"Bb2\",  2: \"B2\",   3: \"C3\",\n",
    "                      4: \"Db3\",  5: \"D3\",   6: \"Eb3\",  7: \"E3\", \n",
    "                      8: \"F3\",   9: \"Gb3\", 10: \"G3\",  11: \"Ab3\",\n",
    "                     12: \"A3\",  13: \"Bb3\", 14: \"B3\",  15: \"C4\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data references\n",
    "Read the reference csv to relevant data structure.\n",
    "\n",
    "`data_ref_list` is the list of filenames in the dataset in a 3d array format.\n",
    "A specific file is accessed with `data_ref_list[vowel_idx][pitch_idx][person_idx]`.\n",
    "\n",
    "`flat_data_ref_list` is the list of filenames in the dataset as a 1d array. To access a specific file, use `flat_data_ref_list[flat_ref_idx(vowel, pitch, person)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# e.g. data_list[vowel_to_label[\"dog\"]][5][1]\n",
    "data_ref_list = create_data_ref_list(os.path.join(\"Data\", 'dataset_files.csv'),\n",
    "                                     n_pitches, n_vowels, n_people)\n",
    "# print(data_ref_list)\n",
    "# e.g. flat_data_ref_list[flat_ref_idx(3, 1, 2)]\n",
    "flat_data_ref_list = flatten_3d_array(data_ref_list, \n",
    "                                      n_vowels, n_pitches, n_people)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following are the accessor functions used to compute indices from flat to 3d and vice versa.\n",
    "\n",
    "`flat_ref_idx` returns a `flat_ref_idx`, given a `(vowel, pitch, person)`, while `nd_ref_idx` returns `vowel, pitch, person`, given a `flat_ref_idx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a flat_ref_idx, given a vowel, pitch, person\n",
    "flat_ref_idx = lambda vowel, pitch, person: flat_3d_array_idx(\n",
    "    vowel, pitch, person, n_vowels, n_pitches, n_people)\n",
    "# Returns vowel, pitch, person, given a flat_ref_idx\n",
    "nd_ref_idx = lambda idx: nd_array_idx(idx, n_vowels, n_pitches, n_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Data ref list ({}):\".format(len(flat_data_ref_list)), \n",
    "      flat_data_ref_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data-label Pitch Index pairs\n",
    "Generate the data-label pitch index pairs. This is an array where each element is a 3-tuple of `[shift_amt, input_pitch_idx, label_pitch_iIdx]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_label_pairs, _ = create_data_label_pairs(n_pitches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Total data-label pairs ({}):\".format(len(data_label_pairs)), \n",
    "      data_label_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get All .wav Data\n",
    "Get the wav file data into a single matrix, where each element `all_wav_data[idx]` is the wavfile content of the file at `flat_data_ref_list[idx]`. To retrieve the 3d indices of a specific index, use `vowel, pitch, person = nd_ref_idx(idx)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wav_data = load_wav_files(os.path.join(\"Data\", \"dataset\"), \n",
    "                              flat_data_ref_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All wav data length: {}\\nTrack length: {}\".format(\n",
    "      all_wav_data.shape, all_wav_data[0].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create all spectrograms\n",
    "Get the spectrograms for each wav in `all_wav_data`. The spectrogram at `all_spectrograms[idx]` is the spectrogram of the wav at `all_wav_data[idx]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_spectrograms = np.array([ stft(waveform, plot=False) \n",
    "                              for waveform in all_wav_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All spectrograms has shape: {} (n_wavs, n_freq_bins, n_windows)\\n\"\n",
    "      .format(all_spectrograms.shape))\n",
    "\n",
    "print(\"FFT Spectrogram of vowel 4, pitch 3, person 2 ({}):\"\n",
    "      .format(flat_data_ref_list[flat_ref_idx(4, 3, 2)]))\n",
    "plot_ffts_spectrogram(all_spectrograms[flat_ref_idx(4, 3, 2)], sample_rate,\n",
    "                      flat_data_ref_list[flat_ref_idx(4, 3, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Mel Spectrograms and MFCC\n",
    "Get the mel spectrograms/MFCC for each ffts (spectrogram) in `all_spectrograms` (similar indexing as above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mels, all_mfcc = map(np.array, map(list, zip(*\n",
    "                         [ ffts_to_mel(ffts, n_mels = 128) \n",
    "                           for ffts in all_spectrograms ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"All mels has shape: {} (n_wavs, n_mels, n_windows)\"\n",
    "      .format(all_mels.shape))\n",
    "print(\"All mfccs has shape: {} (n_wavs, n_mfcc, n_windows)\\n\"\n",
    "      .format(all_mfcc.shape))\n",
    "\n",
    "print(\"Mel Spectrogram of vowel 4, pitch 3, person 2 ({}):\"\n",
    "      .format(flat_data_ref_list[flat_ref_idx(4, 3, 2)]))\n",
    "plot_mel_spectrogram(all_mels[flat_ref_idx(4, 3, 2)], sample_rate,\n",
    "                     flat_data_ref_list[flat_ref_idx(4, 3, 2)])\n",
    "print(\"MFCC of vowel 4, pitch 3, person 2 ({}):\"\n",
    "      .format(flat_data_ref_list[flat_ref_idx(4, 3, 2)]))\n",
    "plot_mfcc(all_mfcc[flat_ref_idx(4, 3, 2)], sample_rate,\n",
    "          flat_data_ref_list[flat_ref_idx(4, 3, 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
