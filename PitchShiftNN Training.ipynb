{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PitchShiftNN Training\n",
    "This is the notebook used to train the Vocal Pitch Modulator.\n",
    "\n",
    "## Global variables/Imports\n",
    "Run these cells before running either of the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import scipy.io as sio\n",
    "from scipy.io import wavfile\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import subplots\n",
    "\n",
    "import time\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, log_loss\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from IPython.display import HTML\n",
    "import warnings\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "%aimport VPM\n",
    "from VPM import *\n",
    "%aimport Utils\n",
    "from Utils import *\n",
    "%aimport PitchShiftNN\n",
    "from PitchShiftNN import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants that should not change without the dataset being changed\n",
    "n_pitches = 16\n",
    "n_vowels = 12\n",
    "n_people = 3\n",
    "\n",
    "# These dictionaries are more for reference than anything\n",
    "label_to_vowel = { 0: \"bed\",  1: \"bird\",   2: \"boat\",  3: \"book\", \n",
    "                   4: \"cat\",  5: \"dog\",    6: \"feet\",  7: \"law\",  \n",
    "                   8: \"moo\",  9: \"nut\",   10: \"pig\",  11: \"say\" }\n",
    "\n",
    "vowel_to_label = { \"bed\": 0,  \"bird\": 1,  \"boat\":  2, \"book\":  3,\n",
    "                   \"cat\": 4,  \"dog\":  5,  \"feet\":  6, \"law\":   7,\n",
    "                   \"moo\": 8,  \"nut\":  9,  \"pig\":  10, \"say\":  11}\n",
    "\n",
    "noteidx_to_pitch = {  0: \"A2\",   1: \"Bb2\",  2: \"B2\",   3: \"C3\",\n",
    "                      4: \"Db3\",  5: \"D3\",   6: \"Eb3\",  7: \"E3\", \n",
    "                      8: \"F3\",   9: \"Gb3\", 10: \"G3\",  11: \"Ab3\",\n",
    "                     12: \"A3\",  13: \"Bb3\", 14: \"B3\",  15: \"C4\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation\n",
    "This is copied directly from `Data Processing for Training PitchShiftNN.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# e.g. data_list[vowel_to_label[\"dog\"]][5][1]\n",
    "data_ref_list = create_data_ref_list(os.path.join(\"Data\", 'dataset_files.csv'),\n",
    "                                     n_pitches, n_vowels, n_people)\n",
    "\n",
    "# e.g. flat_data_ref_list[flat_ref_idx(3, 1, 2)]\n",
    "flat_data_ref_list = flatten_3d_array(data_ref_list, \n",
    "                                      n_vowels, n_pitches, n_people)\n",
    "\n",
    "# Returns a flat_ref_idx, given a vowel, pitch, person\n",
    "flat_ref_idx = lambda vowel, pitch, person: flat_3d_array_idx(\n",
    "    vowel, pitch, person, n_vowels, n_pitches, n_people)\n",
    "\n",
    "# Returns vowel, pitch, person, given a flat_ref_idx\n",
    "nd_ref_idx = lambda idx: nd_array_idx(idx, n_vowels, n_pitches, n_people)\n",
    "\n",
    "data_label_pairs, data_label_pairs_dict = create_data_label_pairs(n_pitches)\n",
    "\n",
    "all_wav_data = load_wav_files(os.path.join(\"Data\", \"dataset\"), \n",
    "                              flat_data_ref_list)\n",
    "all_spectrograms = np.array([ stft(waveform, plot=False) for waveform in all_wav_data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22272, 513)\n",
      "(22272, 513)\n",
      "(11136, 513)\n",
      "(11136, 513)\n",
      "(22272, 513)\n",
      "(11136, 513)\n",
      "(22272, 1026)\n",
      "(11136, 1026)\n"
     ]
    }
   ],
   "source": [
    "# EDIT THE SHIFT AMOUNT PARAMETER HERE\n",
    "\n",
    "shift_amt = 0\n",
    "pairs = data_label_pairs_dict[shift_amt]\n",
    "\n",
    "# X_train_base, Y_train: (_,513), (_,513)\n",
    "# X_val_base, Y_val:     (_,513), (_,513)\n",
    "\n",
    "X_train_base = []; X_val_base = []; Y_train = []; Y_val = []\n",
    "\n",
    "for vow_idx in range(n_vowels):\n",
    "    for pit_idx in range(n_pitches):\n",
    "        \n",
    "        # If the pair is valid, then proceed.\n",
    "        if [shift_amt, pit_idx, pit_idx + shift_amt] in pairs:\n",
    "        \n",
    "            # Choose the person for this pitch/vowel to be used as test data.\n",
    "            test_pid = int(np.random.rand() * 3)\n",
    "\n",
    "            for pid_idx in range(n_people):\n",
    "                wav_idx = flat_ref_idx(vow_idx, pit_idx, pid_idx)\n",
    "                wav_idx_shifted = flat_ref_idx(vow_idx, pit_idx + shift_amt, pid_idx)\n",
    "\n",
    "                if (pid_idx != test_pid):\n",
    "                    X_train_base.extend(all_spectrograms[wav_idx].T)\n",
    "                    Y_train.extend(all_spectrograms[wav_idx_shifted].T)\n",
    "                else:\n",
    "                    X_val_base.extend(all_spectrograms[wav_idx].T)\n",
    "                    Y_val.extend(all_spectrograms[wav_idx_shifted].T)\n",
    "\n",
    "X_train_base = np.array(X_train_base); Y_train = np.array(Y_train); X_val_base = np.array(X_val_base); Y_val = np.array(Y_val); \n",
    "                    \n",
    "print(X_train_base.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_val_base.shape)\n",
    "print(Y_val.shape)\n",
    "\n",
    "X_train_shifted = np.array([ simple_fft_pitch_shift(x, shift_amt) for x in X_train_base ])\n",
    "X_val_shifted = np.array([ simple_fft_pitch_shift(x, shift_amt) for x in X_val_base ])\n",
    "\n",
    "print(X_train_shifted.shape)\n",
    "print(X_val_shifted.shape)\n",
    "\n",
    "# X_train, X_val: (_,1026 = 513*2), (_,1026 = 513*2)\n",
    "\n",
    "X_train = np.hstack((X_train_base,X_train_shifted))\n",
    "X_val = np.hstack((X_val_base,X_val_shifted))\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "\n",
    "X_train = np.absolute(X_train)\n",
    "X_val = np.absolute(X_val)\n",
    "Y_train = np.absolute(Y_train)\n",
    "Y_val = np.absolute(Y_val)\n",
    "\n",
    "# Turn into PyTorch tensor format\n",
    "\n",
    "X_train, Y_train, X_val, Y_val = map(torch.tensor, (X_train, Y_train, X_val, Y_val))\n",
    "X_train = X_train.float(); X_val = X_val.float()\n",
    "Y_train = Y_train.float(); Y_val = Y_val.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PitchShiftNN\n",
    "\n",
    "Input: `(original window, manual pitch shifted window)`\n",
    "\n",
    "Output: `(natural pitch shifted window)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_input = 1026; n_hid = 513; n_output = 513; \n",
    "n_epochs = 5000; lr = 0.2;\n",
    "\n",
    "# Define model\n",
    "model = PitchShiftNN(n_input = n_input, n_hid = n_hid, n_output = n_output)\n",
    "\n",
    "# Define loss \n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Available\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU Available\" if torch.cuda.is_available() else \"GPU Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([22272, 1026])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc917c29ccf4406bd347630cfec70d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Training', max=5000.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 4.00 GiB total capacity; 3.04 GiB already allocated; 14.67 MiB free; 3.09 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7cba21624198>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mtic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m loss = model.train_func(X_train, Y_train, X_val, Y_val, model, opt,\n\u001b[1;32m---> 20\u001b[1;33m                         loss_fn, epochs=n_epochs, print_graph=True)\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Final loss: {}\\nTime taken: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtoc\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\core\\education\\nus2020\\cs4347\\group-project\\VocalPitchModulator\\PitchShiftNN.py\u001b[0m in \u001b[0;36mtrain_func\u001b[1;34m(self, x, y, x_val, y_val, model, opt, loss_fn, epochs, print_graph)\u001b[0m\n\u001b[0;32m     72\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[0mopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m             \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\core\\education\\nus2020\\cs4347\\group-project\\VocalPitchModulator\\PitchShiftNN.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \u001b[0mh2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprint_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\activation.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mrelu\u001b[1;34m(input, inplace)\u001b[0m\n\u001b[0;32m    912\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 44.00 MiB (GPU 0; 4.00 GiB total capacity; 3.04 GiB already allocated; 14.67 MiB free; 3.09 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "# Use GPU if possible (will run on CPU otherwise)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Move inputs to GPU (if possible)\n",
    "X_train = X_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "Y_val = Y_val.to(device)\n",
    "\n",
    "# Move the network to GPU (if possible)\n",
    "model.to(device) \n",
    "\n",
    "# Define optimizer \n",
    "opt = optim.SGD(model.parameters(), lr=lr)\n",
    "# opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Fit the model\n",
    "tic = time.time()\n",
    "loss = model.train_func(X_train, Y_train, X_val, Y_val, model, opt,\n",
    "                        loss_fn, epochs=n_epochs, print_graph=True)\n",
    "toc = time.time()\n",
    "print('Final loss: {}\\nTime taken: {}'.format(loss, toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "model_path = os.path.join(\"model_data\", \"TimbreEncoder_{}_{}_{}_{}_{}_{}.pt\"\n",
    "                          .format(lr, n_epochs, n_mfcc, n_hid, n_timb, loss))\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved at {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the saved model, and using the model for prediction (whole dataset) example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimbreEncoder(n_mfcc=n_mfcc, n_hid=n_hid, n_timb=n_timb, n_vowels=n_vowels)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "# model.to(device)\n",
    "\n",
    "data_tensor, label_tensor = map(torch.tensor, (data, labels))\n",
    "data_tensor = data_tensor.float(); label_tensor = label_tensor.long(); \n",
    "# data_tensor = data_tensor.to(device); label_tensor = label_tensor.to(device)\n",
    "\n",
    "correct = 0; wrong = 0;\n",
    "corrects = np.zeros(n_vowels); wrongs = np.zeros(n_vowels)\n",
    "predictions = np.zeros((n_vowels, n_vowels));\n",
    "for vowel_idx in range(n_vowels):\n",
    "    for pitch_idx in range(n_pitches):\n",
    "        for pid_idx in range(n_people):\n",
    "            wav_idx = flat_ref_idx(vowel_idx, pitch_idx, pid_idx)\n",
    "            for win_idx in range(n_windows):\n",
    "                data_idx = flat_data_idx(wav_idx, win_idx)\n",
    "                label = (label_tensor[data_idx]).item()\n",
    "                pred = (torch.argmax(model(data_tensor[data_idx]))).item()\n",
    "                \n",
    "                predictions[vowel_idx][pred] = predictions[vowel_idx][pred] + 1\n",
    "                if label == pred:\n",
    "                    correct = correct + 1\n",
    "                    corrects[vowel_idx] = corrects[vowel_idx] + 1\n",
    "                else:\n",
    "                    wrong = wrong + 1\n",
    "                    wrongs[vowel_idx] = wrongs[vowel_idx] + 1\n",
    "                    \n",
    "print(\"Total Accuracy: {}\"\n",
    "      .format(correct / (wrong + correct)))\n",
    "for vowel_idx in range(n_vowels):\n",
    "    print(\"Vowel: {}. Accuracy: {}. Most common pred: {}\"\n",
    "          .format(label_to_vowel[vowel_idx],\n",
    "                  corrects[vowel_idx] / (wrongs[vowel_idx] + corrects[vowel_idx]),\n",
    "                  label_to_vowel[np.argmax(predictions[vowel_idx])]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timbre-VAE - MFCC -> MFCC\n",
    "This takes MFCC, reduces dimensionality to a `n_timb` latent space, and attempts to recreate the MFCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hid = 10; n_timb = 4; lr = 1e-3; n_epochs = 10000; batch_size=22272\n",
    "\n",
    "# Training model \n",
    "model = TimbreVAE(n_mfcc=n_mfcc, n_hid=n_hid, n_timb=n_timb)\n",
    "\n",
    "# Define loss - from pytorch VAE example.\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GPU Available\" if torch.cuda.is_available() else \"GPU Not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use GPU if possible (will run on CPU otherwise)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "# Move inputs to GPU (if possible)\n",
    "X_train = X_train.to(device)\n",
    "X_val = X_val.to(device)\n",
    "\n",
    "# Move the network to GPU (if possible)\n",
    "model.to(device) \n",
    "# Define optimizer \n",
    "# opt = optim.SGD(model.parameters(), lr=lr)\n",
    "opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Fit the model\n",
    "tic = time.time()\n",
    "loss = model.train_func(X_train, X_val, model, opt, loss_fn, batch_size=batch_size,\n",
    "                        epochs=n_epochs, print_graph = True)\n",
    "toc = time.time()\n",
    "print('Final loss: {}\\nTime taken: {}'.format(loss, toc - tic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "model_path = os.path.join(\"model_data\", \"TimbreVAE_{}_{}_{}_{}_{}_{}_{}.pt\"\n",
    "                          .format(lr, n_epochs, n_mfcc, n_hid, n_timb, batch_size, loss))\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved at {}\".format(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the saved model, and using the model for prediction example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TimbreVAE(n_mfcc=n_mfcc, n_hid=n_hid, n_timb=n_timb, n_vowels=n_vowels)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "data_tensor = torch.tensor(data)\n",
    "data_tensor = data_tensor.float();\n",
    "\n",
    "wav_idx = flat_ref_idx(5, 5, 1)\n",
    "data_idx = flat_data_idx(wav_idx, 30)\n",
    "label = data_tensor[data_idx]\n",
    "pred = model(data_tensor[data_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment: Choosing `n_hid`, `n_timb`\n",
    "\n",
    "From running this, we find the results:\n",
    "Best `n_hid`: 10, Best `n_timb`: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65d296f7d35d4c74acf7f46dab5925ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 6, n_timb: 4', max=2500.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 6, n_timb: 4, Final val loss: 12.756245229436063, Time taken: 24.036638021469116\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_6_4_12.756245229436063.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "637a70bd5180424cb248d25fc7782aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 8, n_timb: 4', max=2500.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 8, n_timb: 4, Final val loss: 12.756556719198993, Time taken: 23.402870178222656\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_8_4_12.756556719198993.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4631374efbbf4dd393a26627aaf5e0b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 8, n_timb: 6', max=2500.0, style=ProgressStyle(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 8, n_timb: 6, Final val loss: 12.757583793552442, Time taken: 24.187214136123657\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_8_6_12.757583793552442.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1234f6522da7490f8fea6ba030324f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 10, n_timb: 4', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 10, n_timb: 4, Final val loss: 12.755354256465518, Time taken: 23.62875461578369\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_10_4_12.755354256465518.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bffe0fb4c21e4813a77fe5e903c54b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 10, n_timb: 6', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 10, n_timb: 6, Final val loss: 12.756701239224139, Time taken: 23.57104468345642\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_10_6_12.756701239224139.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3ffe45c5104ad68621a431a255b167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 10, n_timb: 8', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 10, n_timb: 8, Final val loss: 12.75628732264727, Time taken: 23.87569832801819\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_10_8_12.75628732264727.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cfdae241df14f52b49ad43e45a25f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 12, n_timb: 4', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 12, n_timb: 4, Final val loss: 12.75652725395115, Time taken: 23.377437353134155\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_12_4_12.75652725395115.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bdd35cf8da4354b09ed4e8ef78ad9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 12, n_timb: 6', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 12, n_timb: 6, Final val loss: 12.756516029094827, Time taken: 24.132755041122437\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_12_6_12.756516029094827.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80524de2ec654ee5acf77ad615f62c09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 12, n_timb: 8', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 12, n_timb: 8, Final val loss: 12.757957020025144, Time taken: 21.46918272972107\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_12_8_12.757957020025144.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bcd9d9a0a3343c9a7652928ae3ff05c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 12, n_timb: 10', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 12, n_timb: 10, Final val loss: 12.757127783764368, Time taken: 24.31379532814026\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_12_10_12.757127783764368.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8c7d87690647749f976883fcee2983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 14, n_timb: 4', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 14, n_timb: 4, Final val loss: 12.75653426948635, Time taken: 23.120083808898926\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_14_4_12.75653426948635.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549a86014cec4551b236af68296f1858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 14, n_timb: 6', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 14, n_timb: 6, Final val loss: 12.75579904139727, Time taken: 23.299814462661743\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_14_6_12.75579904139727.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f86b8c40f744bbb90b1b531ebcb35a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 14, n_timb: 8', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 14, n_timb: 8, Final val loss: 12.757596421515805, Time taken: 24.524491548538208\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_14_8_12.757596421515805.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277dd35e7e734f41aa39c29bc911df44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 14, n_timb: 10', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 14, n_timb: 10, Final val loss: 12.756250841864224, Time taken: 24.066789388656616\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_14_10_12.756250841864224.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddccc7066410466cbdd1f752cbcedcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 14, n_timb: 12', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 14, n_timb: 12, Final val loss: 12.757847577676007, Time taken: 23.379464149475098\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_14_12_12.757847577676007.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77a68e0d1ad433f9c96b54812956090",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 4', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 4, Final val loss: 12.75629153196839, Time taken: 23.141919136047363\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_4_12.75629153196839.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29807120aed403587af8f2212b5cfa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 6', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 6, Final val loss: 12.75677841011135, Time taken: 23.408835649490356\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_6_12.75677841011135.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbd525a318d4eb3858a38987e7fbc5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 8', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 8, Final val loss: 12.757703057650861, Time taken: 23.205310583114624\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_8_12.757703057650861.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164ad8405d7141fc9240f6a1c2167747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 10', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 10, Final val loss: 12.756217167295258, Time taken: 18.973145723342896\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_10_12.756217167295258.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb355397ada040c6a7f8bf467ec87881",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 12', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 12, Final val loss: 12.756746138649426, Time taken: 18.91083335876465\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_12_12.756746138649426.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6f9708fc6b43bea0f2924e35c104b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 16, n_timb: 14', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 16, n_timb: 14, Final val loss: 12.757397180316092, Time taken: 19.097800970077515\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_16_14_12.757397180316092.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b581abac8004f38b745c698ece54d8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 4', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 4, Final val loss: 12.756252244971265, Time taken: 18.403200149536133\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_4_12.756252244971265.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5c5069a36242f096ed402dba273109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 6', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 6, Final val loss: 12.755765366828305, Time taken: 20.536202669143677\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_6_12.755765366828305.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8c0252adfb4320b68b49d0684bb304",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 8', max=2500.0, style=ProgressStyle(de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 8, Final val loss: 12.756218570402298, Time taken: 18.79640245437622\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_8_12.756218570402298.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785fe56719e345f5b9911198c0e7a7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 10', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 10, Final val loss: 12.757287737966953, Time taken: 19.083486557006836\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_10_12.757287737966953.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69588899cbf04340b123a9f65a4a3c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 12', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 12, Final val loss: 12.757718491828305, Time taken: 19.04806160926819\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_12_12.757718491828305.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39afd0e0656a482c94401b5f7a4a7caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 14', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 14, Final val loss: 12.75823904454023, Time taken: 19.794686317443848\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_14_12.75823904454023.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b3e05805e848aa9c6decf75e2f9a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='n_hid: 18, n_timb: 16', max=2500.0, style=ProgressStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "n_hid: 18, n_timb: 16, Final val loss: 12.756389749461206, Time taken: 18.548084497451782\n",
      "Model saved at model_data\\TimbreVAE_n_hid_n_timb_experiment_18_16_12.756389749461206.pt\n"
     ]
    }
   ],
   "source": [
    "# Define loss - from pytorch VAE example.\n",
    "def loss_fn(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD\n",
    "\n",
    "n_hid_candidates = [6, 8, 10, 12, 14, 16, 18]\n",
    "n_timb_candidates = [4, 6, 8, 10, 12, 14, 16]\n",
    "lr = 1e-3; n_epochs = 2500; batch_size=22272\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "losses = []\n",
    "for hid_idx in range(len(n_hid_candidates)):\n",
    "    for timb_idx in range(len(n_timb_candidates)):\n",
    "        if (hid_idx < timb_idx): continue\n",
    "        n_hid = n_hid_candidates[hid_idx]\n",
    "        n_timb = n_timb_candidates[timb_idx]\n",
    "        \n",
    "        # Training model \n",
    "        model = TimbreVAE(n_mfcc=n_mfcc, n_hid=n_hid, n_timb=n_timb)\n",
    "\n",
    "        X_train = X_train.to(device)\n",
    "        X_val = X_val.to(device)\n",
    "        model.to(device) \n",
    "        # opt = optim.SGD(model.parameters(), lr=lr)\n",
    "        opt = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "        # Fit the model\n",
    "        tic = time.time()\n",
    "        loss, val_loss = model.train_func(X_train, X_val, model, opt, loss_fn, batch_size=batch_size,\n",
    "                                epochs=n_epochs, print_graph=False, desc=\"n_hid: {}, n_timb: {}\".format(n_hid, n_timb))\n",
    "        toc = time.time()\n",
    "        print('n_hid: {}, n_timb: {}, Final val loss: {}, Time taken: {}'.format(n_hid, n_timb, val_loss, toc - tic))\n",
    "        model_path = os.path.join(\"model_data\", \"TimbreVAE_n_hid_n_timb_experiment_{}_{}_{}.pt\"\n",
    "                                  .format(n_hid, n_timb, val_loss))\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        print(\"Model saved at {}\".format(model_path)) \n",
    "        losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best n_hid: 10, Best n_timb: 4\n",
      "[[12.756245229436063 list([6, 4])]\n",
      " [12.756556719198993 list([8, 4])]\n",
      " [12.757583793552442 list([8, 6])]\n",
      " [12.755354256465518 list([10, 4])]\n",
      " [12.756701239224139 list([10, 6])]\n",
      " [12.75628732264727 list([10, 8])]\n",
      " [12.75652725395115 list([12, 4])]\n",
      " [12.756516029094827 list([12, 6])]\n",
      " [12.757957020025144 list([12, 8])]\n",
      " [12.757127783764368 list([12, 10])]\n",
      " [12.75653426948635 list([14, 4])]\n",
      " [12.75579904139727 list([14, 6])]\n",
      " [12.757596421515805 list([14, 8])]\n",
      " [12.756250841864224 list([14, 10])]\n",
      " [12.757847577676007 list([14, 12])]\n",
      " [12.75629153196839 list([16, 4])]\n",
      " [12.75677841011135 list([16, 6])]\n",
      " [12.757703057650861 list([16, 8])]\n",
      " [12.756217167295258 list([16, 10])]\n",
      " [12.756746138649426 list([16, 12])]\n",
      " [12.757397180316092 list([16, 14])]\n",
      " [12.756252244971265 list([18, 4])]\n",
      " [12.755765366828305 list([18, 6])]\n",
      " [12.756218570402298 list([18, 8])]\n",
      " [12.757287737966953 list([18, 10])]\n",
      " [12.757718491828305 list([18, 12])]\n",
      " [12.75823904454023 list([18, 14])]\n",
      " [12.756389749461206 list([18, 16])]]\n"
     ]
    }
   ],
   "source": [
    "indices = [ [n_hid_candidates[hid_idx], n_timb_candidates[timb_idx]] \n",
    "            for hid_idx in range(len(n_hid_candidates))\n",
    "            for timb_idx in range(len(n_timb_candidates)) if (hid_idx >= timb_idx) ]\n",
    "best_hid, best_timb = indices[np.argmin(np.array(losses))]\n",
    "print(\"Best n_hid: {}, Best n_timb: {}\".format(best_hid, best_timb))\n",
    "print(np.array(list(zip(losses, indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
